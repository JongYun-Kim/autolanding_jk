defaults:
  - _self_
  - task@_global_: landing-aviary-v0-gimbal-curriculum
  - curriculum_preset: balanced  # conservative | balanced | aggressive
  - encoder_bundle@agent: enc_B
  - actor_critic_bundle@agent: original  # original | autoregressive_gimbal_first | autoregressive_drone_first | multihead_attention | multihead_attention_factored
  - override hydra/launcher: submitit_local

# task settings
frame_stack: 3
action_repeat: 1
discount: 0.99
# train settings
num_seed_frames: 4800
# eval
eval_every_frames: 30000
num_eval_episodes: 10
num_post_eval_episodes: 500
# snapshot
save_snapshot: true
# replay buffer
replay_buffer_size: 400000
replay_buffer_num_workers: 4
nstep: 3
batch_size: 512
# misc
seed: 1
device: cuda
save_video: true
save_train_video: false
use_tb: true
# experiment
experiment: exp
# agent
lr: 1.0e-4
feature_dim: 128

agent:
  _target_: drqv2-w-new_nets.DrQV2Agent
  obs_shape: ??? # to be specified later
  action_shape: ??? # to be specified later
  device: ${device}
  lr: ${lr}
  critic_target_tau: 0.05
  update_every_steps: 2
  use_tb: ${use_tb}
  num_expl_steps: 2000
  hidden_dim: 512
  feature_dim: ${feature_dim}
  stddev_schedule: ${stddev_schedule}
  stddev_clip: 0.32
  frame_stack: ${frame_stack}

hydra:
  run:
    dir: ./exp_local/${now:%Y.%m.%d}/${now:%H%M%S}_${hydra.job.override_dirname}
  sweep:
    dir: ./exp/${now:%Y.%m.%d}/${now:%H%M}_${agent_cfg.experiment}
    subdir: ${hydra.job.num}
  launcher:
    timeout_min: 4300
    cpus_per_task: 10
    gpus_per_node: 1
    tasks_per_node: 1
    mem_gb: 100
    nodes: 1
    submitit_folder: ./exp/${now:%Y.%m.%d}/${now:%H%M%S}_${agent_cfg.experiment}/.slurm
