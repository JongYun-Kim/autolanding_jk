# @package _global_

# Smooth exponential decay schedule
# Recommended for continuous, gradual learning rate reduction
#
# Strategy:
# - Continuous exponential decay instead of discrete steps
# - Gentle decay rate (0.9995) applied every 10K steps
# - Provides smooth transition without sudden changes
# - Different phases with adjusted decay rates
#
# Best for: Sensitive tasks, avoiding training instabilities, smooth convergence

lr_schedule:
  encoder:
    type: exponential_decay
    intervals:
      - {start: 0, end: 3000000, init_lr: 1.0e-4, decay_rate: 0.9995, decay_interval: 10000}
      - {start: 3000000, end: 10000000, init_lr: 5.0e-5, decay_rate: 0.999, decay_interval: 10000}

  actor:
    type: exponential_decay
    intervals:
      - {start: 0, end: 3000000, init_lr: 1.0e-4, decay_rate: 0.9995, decay_interval: 10000}
      - {start: 3000000, end: 10000000, init_lr: 5.0e-5, decay_rate: 0.999, decay_interval: 10000}

  critic:
    type: exponential_decay
    intervals:
      - {start: 0, end: 3000000, init_lr: 1.0e-4, decay_rate: 0.9995, decay_interval: 10000}
      - {start: 3000000, end: 10000000, init_lr: 5.0e-5, decay_rate: 0.999, decay_interval: 10000}
