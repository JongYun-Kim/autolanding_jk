# @package _global_

# Gentle step decay schedule
# Recommended for stable training with gradual performance improvement
#
# Strategy:
# - Starts with default LR (1e-4) for initial learning phase
# - Reduces to 50% at 2M steps when agent shows competence
# - Further reduces to 25% at 4M steps for fine-tuning
# - Same schedule for all networks to maintain balanced learning
#
# Best for: Standard training, risk-averse approach, baseline experiments

lr_schedule:
  encoder:
    type: step_decay
    intervals:
      - {start: 0, end: 2000000, lr: 1.0e-4}
      - {start: 2000000, end: 4000000, lr: 5.0e-5}
      - {start: 4000000, end: 10000000, lr: 2.5e-5}

  actor:
    type: step_decay
    intervals:
      - {start: 0, end: 2000000, lr: 1.0e-4}
      - {start: 2000000, end: 4000000, lr: 5.0e-5}
      - {start: 4000000, end: 10000000, lr: 2.5e-5}

  critic:
    type: step_decay
    intervals:
      - {start: 0, end: 2000000, lr: 1.0e-4}
      - {start: 2000000, end: 4000000, lr: 5.0e-5}
      - {start: 4000000, end: 10000000, lr: 2.5e-5}
