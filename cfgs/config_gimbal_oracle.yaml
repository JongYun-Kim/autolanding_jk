defaults:
  - _self_
  - task@_global_: landing-aviary-v0-gimbal-oracle
  - override hydra/launcher: submitit_local

# task settings
frame_stack: 3
action_repeat: 1
discount: 0.99
# train settings
num_seed_frames: 4800
# eval
eval_every_frames: 30000
num_eval_episodes: 10
num_post_eval_episodes: 500
# snapshot
save_snapshot: true
# replay buffer
replay_buffer_size: 300000
replay_buffer_num_workers: 4
nstep: 3
batch_size: 256
# misc
seed: 1
device: cuda
save_video: true
save_train_video: false
use_tb: true
# experiment
experiment: exp
# agent
lr: 1.0e-4 #for reduced size network LR is set seprately in train.py check!
feature_dim: 50

agent:
  _target_: drqv2.DrQV2Agent
  obs_shape: ??? # to be specified later
  action_shape: ??? # to be specified later
  device: ${device}
  lr: ${lr}
  critic_target_tau: 0.05
  update_every_steps: 2
  use_tb: ${use_tb}
  num_expl_steps: 2000
  hidden_dim: 512
  feature_dim: ${feature_dim}
  stddev_schedule: ${stddev_schedule}
  stddev_clip: 0.3

env:
  train:
    is_noisy_gimbal: False
  eval:
    is_noisy_gimbal: False

hydra:
  run:
    dir: ./exp_local/${now:%Y.%m.%d}/${now:%H%M%S}_${hydra.job.override_dirname}
    #dir: /home/user/landing/drqv2_landing/exp_local/2023.06.30/073323_task=landing-aviary-v0
  sweep:
    dir: ./exp/${now:%Y.%m.%d}/${now:%H%M}_${agent_cfg.experiment}
    subdir: ${hydra.job.num}
  launcher:
    timeout_min: 4300
    cpus_per_task: 10
    gpus_per_node: 1
    tasks_per_node: 1
    mem_gb: 100
    nodes: 1
    submitit_folder: ./exp/${now:%Y.%m.%d}/${now:%H%M%S}_${agent_cfg.experiment}/.slurm
